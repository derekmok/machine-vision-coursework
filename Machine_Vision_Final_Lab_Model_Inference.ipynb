{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "view-in-github"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/derekmok/machine-vision-coursework/blob/main/Machine_Vision_Final_Lab_Model_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bSu3U-SNu8v6",
    "outputId": "5ddf74be-2b61-4815-ce8a-5c180ac9858a"
   },
   "outputs": [],
   "source": [
    "# ===== INSTALL DEPENDENCIES =====\n",
    "!git init .\n",
    "!git remote add origin https://github.com/derekmok/machine-vision-coursework.git\n",
    "!git pull origin main\n",
    "\n",
    "!pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3Lo27xcqrOMq"
   },
   "outputs": [],
   "source": [
    "# Import the required libraries\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from huggingface_hub import hf_hub_download\n",
    "import boto3\n",
    "from botocore import UNSIGNED\n",
    "from botocore.config import Config\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PMr99Yo7x8N1"
   },
   "source": [
    "# Please double, triple, quadruple check that the below code runs without errors before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4YhoE1nF2Pee"
   },
   "source": [
    "## TODO 1 - Enter your HuggingFace username below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENyfncieqs6i",
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "hf_username = \"derekmok\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0lC0jUquq_06"
   },
   "source": [
    "## TODO 2 - Define your model EXACTLY as you did in your training code (otherwise there will be errors, and, possibly, tears).\n",
    "\n",
    "Note below the classname is 'YourModelArchitecture'. That's because it literally needs to be YOUR MODEL ARCHITECTURE. This class definition is later referred to below in the 'load_model_from_hub' method. The architecture must match here, or it will not be able to instantiate the model weights correctly once it downloads them from HuggingFace. Pay very close attention to getting this right, please.\n",
    "\n",
    "Replace the below code, and replace the corresponding line in the 'load_model_from_hub' method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cm-y1pPnOGkK"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# 1. MODEL DEFINITION (must match training)\n",
    "# =============================================================================\n",
    "from neural_net.temporal_conv_net import TCNPushUpCounter\n",
    "from neural_net.ensemble_model import EnsembleModel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qahq0xG2rs4h"
   },
   "source": [
    "## Download the test data from s3, and create the corresponding dataset + dataloader.\n",
    "\n",
    "There's no TODO for you here. This text is just here to explain to you what this code does.\n",
    "\n",
    "In this instance, the test data IS the training data you were provided in the Model Training notebook. This is by design. You do not have access to the test data. This is a simple check to make sure the mechanics of this notebook work.\n",
    "\n",
    "You should achieve the same accuracy here in this notebook, as you did in your previous notebook (random seed notwithstanding)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XBukVn9qrnFZ"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DOWNLOAD TEST DATA FROM S3\n",
    "# =============================================================================\n",
    "\n",
    "def download_test_data(bucket_name='training-and-validation-data',download_dir='./test-data'):\n",
    "    s3 = boto3.client('s3', config=Config(signature_version=UNSIGNED))\n",
    "\n",
    "    bucket_name = 'prism-mvta'\n",
    "    prefix = 'training-and-validation-data/'\n",
    "\n",
    "    os.makedirs(download_dir, exist_ok=True)\n",
    "\n",
    "    paginator = s3.get_paginator('list_objects_v2')\n",
    "    pages = paginator.paginate(Bucket=bucket_name, Prefix=prefix)\n",
    "\n",
    "    video_names = []\n",
    "\n",
    "    for page in pages:\n",
    "        if 'Contents' not in page:\n",
    "            print(\"No files found at the specified path!\")\n",
    "            break\n",
    "\n",
    "        print(\"Downloading test data:\\n\")\n",
    "        for obj in tqdm(page['Contents']):\n",
    "            key = obj['Key']\n",
    "            filename = os.path.basename(key)\n",
    "\n",
    "            if not filename:\n",
    "                continue\n",
    "\n",
    "            video_names.append(filename)\n",
    "            local_path = os.path.join(download_dir, filename)\n",
    "            # print(f\"Downloading: {filename}\")\n",
    "            s3.download_file(bucket_name, key, local_path)\n",
    "\n",
    "    print(f\"\\nDownloaded {len(video_names)} test videos\")\n",
    "    return download_dir\n",
    "\n",
    "\n",
    "# ============================================================================= # DATASET AND DATALOADER =============================================================================\n",
    "\n",
    "from neural_net.data_loader import VideoDataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9PVSdWKsP94"
   },
   "source": [
    "## TODO 3 - Download your model from HuggingFace and instantiate it\n",
    "\n",
    "Replace line 8 of the below code. Line 8 is where you instantiate YOUR MODEL ARCHITECTURE (which you re-defined above) with the weights you download from HuggingFace. Make sure you get the class name, and the arguments to the __init__ method correct.\n",
    "\n",
    "\n",
    "This code just downloads the same model which you uploaded in the last notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 194,
     "referenced_widgets": [
      "cfdc1400987345568482d2a09b1bb388",
      "df6c93ec63634bb39453e5a4b0b7718a",
      "d05b7e235252405a841ebd52fb9076e7",
      "f8e5ff077f814a41b4a9fa6f1fe2adc1",
      "7366dc70bfe743bf951be84626837a38",
      "0e788161d33f4a26a1bf3f9fa539dc32",
      "d8cd8f46840a40809e52b19cd6273828",
      "a885dec216b84294ad34b7628c19741f",
      "7e8946e7a8d2476a9acc093f3be5c320",
      "602e1b6c06794838992edb63a52bd236",
      "b900927fbcee4d579949d0c4c1f185d7"
     ]
    },
    "id": "LWuMOqY_sOdg",
    "outputId": "b47126a3-940b-4cc8-b9e1-b837e696fbf0"
   },
   "outputs": [],
   "source": [
    "# =============================================================================\n",
    "# DOWNLOAD MODEL FROM HUGGING FACE\n",
    "# =============================================================================\n",
    "\n",
    "def load_model_from_hub(repo_id, num_classes=10):\n",
    "    model_path = hf_hub_download(repo_id=repo_id, filename=\"model.pt\")\n",
    "\n",
    "    model = EnsembleModel([TCNPushUpCounter(input_channels=6) for _ in range(5)])\n",
    "    model.load_state_dict(torch.load(model_path, map_location='cpu'))\n",
    "\n",
    "    print(f\"Model loaded from {repo_id}\")\n",
    "    return model\n",
    "\n",
    "model = load_model_from_hub(f\"{hf_username}/mv-final-assignment\", num_classes=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NycfLBRksum4"
   },
   "source": [
    "## TODO 4\n",
    "\n",
    "Make sure the below code correctly evaluates your model performance on the given data!\n",
    "\n",
    "This is your last chance to verify this before submission."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QzgdieGiw4_k",
    "outputId": "d2cacecd-19be-4655-cbb9-37ec99be0657"
   },
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader, dataset, device):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "    all_times = []\n",
    "\n",
    "    print(\"\\n\")\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, (frames, labels) in enumerate(test_loader):\n",
    "            frames, labels = frames.to(device), labels.to(device)\n",
    "\n",
    "            # Time the forward pass\n",
    "            start_time = time.time()\n",
    "            outputs = model(frames)\n",
    "            if device.type == 'cuda':\n",
    "                torch.cuda.synchronize()  # wait for GPU to finish\n",
    "            end_time = time.time()\n",
    "\n",
    "            inference_time = (end_time - start_time) * 1000  # ms\n",
    "            all_times.append(inference_time)\n",
    "\n",
    "            # For regression: model returns (count, density_map) tuple\n",
    "            # Extract the count prediction (first element) and round to integer\n",
    "            count_predictions = outputs[0]  # shape: [batch, 1]\n",
    "            preds = torch.round(count_predictions.squeeze(-1)).long()  # shape: [batch]\n",
    "\n",
    "            for i in range(labels.size(0)):\n",
    "                batch_idx = idx * test_loader.batch_size + i\n",
    "                video_name = dataset.video_files[batch_idx]\n",
    "                pred = preds[i].item()\n",
    "                true_label = labels[i].item()\n",
    "                is_correct = \"✓\" if pred == true_label else \"✗\"\n",
    "\n",
    "                print(f\"{is_correct}  pred={pred}  true={true_label}  |  {inference_time:>7.1f}ms  |  {video_name}\")\n",
    "\n",
    "            correct += preds.eq(labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "\n",
    "    accuracy = correct / total\n",
    "    return accuracy, all_preds, all_labels, all_times\n",
    "\n",
    "\n",
    "# =============================================================================\n",
    "# RUN INFERENCE\n",
    "# =============================================================================\n",
    "\n",
    "def run_inference(model, bucket_name='training-and-validation-data'):\n",
    "    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Download test data\n",
    "    test_dir = download_test_data(bucket_name, './test-data')\n",
    "\n",
    "    model = model.to(device)\n",
    "\n",
    "    # Create dataloader\n",
    "    test_dataset = VideoDataset.for_inference(test_dir)\n",
    "    test_loader = DataLoader(\n",
    "        test_dataset,\n",
    "        batch_size=1,\n",
    "        shuffle=False,\n",
    "        num_workers=0\n",
    "    )\n",
    "\n",
    "    print(f\"\\nRunning inference on {len(test_dataset)} test videos...\")\n",
    "\n",
    "    # Warmup (optional, helps get consistent GPU timings)\n",
    "    if device.type == 'cuda':\n",
    "        dummy = torch.randn(1, 1000, 6).to(device)\n",
    "        with torch.no_grad():\n",
    "            _ = model(dummy)\n",
    "        torch.cuda.synchronize()\n",
    "\n",
    "    total_start = time.time()\n",
    "    accuracy, preds, labels, times = evaluate(model, test_loader, test_dataset, device)\n",
    "    total_end = time.time()\n",
    "\n",
    "    # Summary\n",
    "    num_correct = sum(p == l for p, l in zip(preds, labels))\n",
    "    num_wrong = len(preds) - num_correct\n",
    "\n",
    "    print(\"\\n\" + \"=\"*50)\n",
    "    print(\"SUMMARY\")\n",
    "    print(\"=\"*50)\n",
    "    print(f\"Total videos:         {len(preds)}\")\n",
    "    print(f\"Correct:              {num_correct}\")\n",
    "    print(f\"Incorrect:                {num_wrong}\")\n",
    "    print(f\"\")\n",
    "    print(f\"ACCURACY:             {accuracy*100:.2f}%\")\n",
    "    print(f\"\")\n",
    "    print(f\"Total time:           {total_end - total_start:.2f}s\")\n",
    "    print(f\"Avg per video:        {sum(times) / len(times):.1f}ms\")\n",
    "    print(f\"Min latency:          {min(times):.1f}ms\")\n",
    "    print(f\"Max latency:          {max(times):.1f}ms\")\n",
    "    print(\"=\"*50)\n",
    "    return accuracy, preds, labels\n",
    "\n",
    "_, _, _ = run_inference(model)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "include_colab_link": true,
   "provenance": []
  },
  "jupytext": {
   "formats": "ipynb,py:percent"
  },
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0e788161d33f4a26a1bf3f9fa539dc32": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "602e1b6c06794838992edb63a52bd236": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7366dc70bfe743bf951be84626837a38": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "7e8946e7a8d2476a9acc093f3be5c320": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "a885dec216b84294ad34b7628c19741f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b900927fbcee4d579949d0c4c1f185d7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "cfdc1400987345568482d2a09b1bb388": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_df6c93ec63634bb39453e5a4b0b7718a",
       "IPY_MODEL_d05b7e235252405a841ebd52fb9076e7",
       "IPY_MODEL_f8e5ff077f814a41b4a9fa6f1fe2adc1"
      ],
      "layout": "IPY_MODEL_7366dc70bfe743bf951be84626837a38"
     }
    },
    "d05b7e235252405a841ebd52fb9076e7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_a885dec216b84294ad34b7628c19741f",
      "max": 86106,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_7e8946e7a8d2476a9acc093f3be5c320",
      "value": 86106
     }
    },
    "d8cd8f46840a40809e52b19cd6273828": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "df6c93ec63634bb39453e5a4b0b7718a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0e788161d33f4a26a1bf3f9fa539dc32",
      "placeholder": "​",
      "style": "IPY_MODEL_d8cd8f46840a40809e52b19cd6273828",
      "value": "model.pt: 100%"
     }
    },
    "f8e5ff077f814a41b4a9fa6f1fe2adc1": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_602e1b6c06794838992edb63a52bd236",
      "placeholder": "​",
      "style": "IPY_MODEL_b900927fbcee4d579949d0c4c1f185d7",
      "value": " 86.1k/86.1k [00:00&lt;00:00, 121kB/s]"
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
